<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="utf-8">
    <title>draftcode.github.com</title>
    <meta name="author" content="draftcode">
    <meta name="google-site-verification" content="YjRoDozMq67s3NKiyM6spjwqnSVihlZ11ur-OgfZCU0">

    <!--[if lt IE 9]>
    <script src="../theme/html5.js"></script>
    <![endif]-->

    <link href="../theme/bootstrap.min.css" rel="stylesheet">
    <link href="../theme/local.css" rel="stylesheet">
    <link href="../theme/pygments.css" rel="stylesheet">
    <link rel="alternate" type="application/atom+xml" title="Atom" href="../atom.xml">
    <link href='http://fonts.googleapis.com/css?family=Economica' rel='stylesheet'>
</head>

<body>

<h1 id="site-title"><a href="..">draftcode.github.com</a></h1>

<div id="content">


    <div class='article'>
        <div class="content-title">
            <a href="../2012/08/01/5524f2e3-1431-4ee0-b04c-ab89ebdcdf4a.html"><h1>第(1+1)回 六本木 Linux カーネル読書会 参加メモ</h1></a>
            <div class="metadata">
    <span class="label label-inverse">2012/08/01</span>
    <a href="../category/Articles.html" class="label label-info">Articles</a>
</div>        </div>

        <div><p><a class="reference external" href="http://connpass.com/event/824/">第(1+1)回 六本木 Linux カーネル読書会</a>に行ってきたので、そのときのメモ。あまりメモがとれていない。今回はforkとかcloneあたり。</p>
<p>後で調べたこともいくつか追加している。</p>
<div class="topic">
<p class="topic-title first">do_fork (kernel/fork.c)</p>
<p>do_forkはsys_cloneやsys_vfork、sys_forkから呼ばれる。</p>
<dl class="docutils">
<dt>sys_clone</dt>
<dd>arch/x86/kernel/process.c</dd>
<dt>sys_vfork</dt>
<dd>arch/x86/kernel/process.c</dd>
<dt>sys_fork</dt>
<dd>arch/x86/kernel/process.c</dd>
<dt>task_struct</dt>
<dd>include/linux/sched.h</dd>
</dl>
</div>
<div class="topic">
<p class="topic-title first">vfork</p>
<p>古いBSDでfork &amp; execを効率的に行うための仕組み。現在では使われていない。</p>
<p>古いBSDだと、メモリ空間がCopy on Writeではなくて、fork時にコピーするようになっているらしい。このため、fork &amp; execをやろうとすると、無駄にメモリ空間のコピーが走ってしまう。これを防ぐために、vforkというものが生まれた。vforkは子プロセスが親プロセスのメモリ空間を使って動く。このままだと、親プロセスと子プロセスのスタックも共有してしまうので、まず、親プロセスを停止し、次に子プロセスを動かす。子プロセスがexecveを呼ぶかexitするまで、親プロセスは停止する。親プロセスのメモリ空間を利用するため、子プロセスの動きが大きく制約される。</p>
<p><a class="reference external" href="http://surf.ml.seikei.ac.jp/~nakano/JMwww/html/LDP_man-pages/man2/vfork.2.html">http://surf.ml.seikei.ac.jp/~nakano/JMwww/html/LDP_man-pages/man2/vfork.2.html</a></p>
<p>現代的なプログラムではvforkは使ってはいけない。</p>
<p><a class="reference external" href="http://www.jpcert.or.jp/sc-rules/c-pos33-c.html">http://www.jpcert.or.jp/sc-rules/c-pos33-c.html</a></p>
</div>
<div class="topic">
<p class="topic-title first">メモリ空間</p>
<p>カーネル空間とユーザー空間に分かれている。</p>
<dl class="docutils">
<dt>__user</dt>
<dd>include/linux/compiler.h</dd>
<dt>__kernel</dt>
<dd>include/linux/compiler.h</dd>
</dl>
<p>それぞれでメモリ管理をしているので仮想メモリ空間を指すことになる。</p>
</div>
<div class="topic">
<p class="topic-title first">copy_process (kernel/fork.c)</p>
<p>親プロセスのtask_structをコピーしている。</p>
<ul class="simple">
<li>dup_task_structを呼んでる。</li>
<li>sched_forkを呼んでる。</li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">sched_fork (kernel/sched/core.c)</p>
<p>プロセスが実行される前のスケジューラ周りのセットアップを行うみたい。</p>
</div>
<div class="topic">
<p class="topic-title first">dup_task_struct (kernel/fork.c)</p>
<p>task_structのメモリ確保はkmem_cache_alloc_nodeで確保している。</p>
</div>
<div class="topic">
<p class="topic-title first">kmem_cache_alloc_node (include/kernel/slab.h)</p>
<p>カーネル空間のメモリを確保する関数。メモリの種類がいろいろ選べるらしい。</p>
<p><a class="reference external" href="http://www.mech.tohoku-gakuin.ac.jp/rde/contents/linux/drivers/tips1.html">http://www.mech.tohoku-gakuin.ac.jp/rde/contents/linux/drivers/tips1.html</a></p>
<p>kmem_cache_alloc_node の node は tsk_fork_get_node から取ってきている。しかしnodeは無視されてしまう。</p>
</div>
<div class="topic">
<p class="topic-title first">tsk_fork_get_node (kernel/kthread.c)</p>
<p>どうもNUMAアーキテクチャで気にするものらしい。</p>
<p>NUMA は Non-Uniform Memory Access の略で、たしかそれぞれのプロセッサでメモリを持っていて、他のプロセッサが持っているメモリにアクセスするときは、そのプロセッサにお願いして読みに行くというアーキテクチャだったと思う。</p>
</div>
<div class="topic">
<p class="topic-title first">RCUとは</p>
<p>リードコピーアップデート。Wikipedia参照。</p>
<p>どうも、Writerが入るときに、コピーを作ってそっちの方を指すようにする。で、
Readerは読み終わったら上手いことやって、さっきまで見ていた複製元が既に不要になっていたら破棄するようにするものらしい。</p>
<p><a class="reference external" href="http://togetter.com/li/153033">http://togetter.com/li/153033</a></p>
</div>
<div class="topic">
<p class="topic-title first">get_cpu, put_cpu (include/linux/smp.h)</p>
<dl class="docutils">
<dt>get_cpu</dt>
<dd>CPUの割り込みを禁止し、現在のCPUIDを返す。</dd>
<dt>put_cpu</dt>
<dd>CPUの割り込みを有効化。</dd>
</dl>
</div>
<div class="topic">
<p class="topic-title first">wake_up_new_task (kernel/sched/core.c)</p>
<p>do_forkの中で呼び出される。スケジューラに実際に登録する？</p>
</div>
<div class="topic">
<p class="topic-title first">do_execve (fs/exec.c)</p>
<p>これは次回で。</p>
</div>
<div class="topic">
<p class="topic-title first">Buddy memory allocation と Slab allocator</p>
<p>kmem_cache_alloc_node が定義されているのはslab.hなので、slabとは何か調べた。</p>
<p>Buddy memory allocationというメモリアロケーションメカニズムがあって、詳しくはわからないけれど、ページ*2^n単位でメモリを確保していくようなものらしい。これで切り取れるのはページ数単位なので、小さいオブジェクトを確保するのには向いていない。なので間にSlab allocatorというものが入って、小さいオブジェクトを切り出していきましょうという仕組みらしい。mallocと変わらない？いくつかの最適化もされるらしい。</p>
<ul class="simple">
<li><a class="reference external" href="http://en.wikipedia.org/wiki/Buddy_memory_system">http://en.wikipedia.org/wiki/Buddy_memory_system</a></li>
<li><a class="reference external" href="http://wiki.bit-hive.com/linuxkernelmemo/pg/%A5%B9%A5%E9%A5%D6%A5%A2%A5%ED%A5%B1%A1%BC%A5%BF">http://wiki.bit-hive.com/linuxkernelmemo/pg/%A5%B9%A5%E9%A5%D6%A5%A2%A5%ED%A5%B1%A1%BC%A5%BF</a></li>
</ul>
<p>そもそもスラブというものが何かというと、同じサイズのオブジェクトを切り出すためのメモリのことらしい。</p>
<p><a class="reference external" href="http://wiki.bit-hive.com/north/pg/kmalloc(%A5%B9%A5%E9%A5%D6%A5%A2%A5%ED%A5%B1%A1%BC%A5%BF">http://wiki.bit-hive.com/north/pg/kmalloc(%A5%B9%A5%E9%A5%D6%A5%A2%A5%ED%A5%B1%A1%BC%A5%BF</a>)</p>
<p>スラブの割り当て状況みたいなのは/proc/slabinfoで参照できるらしく、さらに
topみたいなslabtopというコマンドもある。</p>
</div>
</div>
        <hr />
    </div>



    <div class='article'>
        <div class="content-title">
            <a href="../2010/08/15/accumulator_programming.html"><h1>アキュムレータについて</h1></a>
            <div class="metadata">
    <span class="label label-inverse">2010/08/15</span>
    <a href="../category/Articles.html" class="label label-info">Articles</a>
</div>        </div>

        <div><p>コンピュータプログラミングの概念・技法・モデルの中で，アキュムレータという概念が出てきました．たぶん，いろいろなところで使ってきた手法を，一般化して名前をつけたため，違うモノのように見えるだけだと思うのですが，混乱しているので整理します．</p>
<div class="section" id="id2">
<h2>再帰計算と反復計算</h2>
<p>宣言的プログラミングにおいては，単純に再帰関数を書いてしまうと効率が悪いことが多いので，現実的には再帰計算の特殊な場合である，反復計算になるようにプログラムを書きます．再帰的データ構造を扱う再帰計算を反復計算にするにあたっては，問題を状態変換の列に作り直す必要がありました．</p>
<p>通常の場合，再帰形を書かずにに反復形を書くことが多いです．その場合に用いられる形式として，アキュムレータプログラミングという形式があります．</p>
</div>
<div class="section" id="id3">
<h2>反復計算におけるアキュムレータ</h2>
<p>反復計算は次のような制御抽象として表現できました:</p>
<div class="highlight"><pre>proc {Iterate S IsDone Transform ?R}
    if {IsDone S} then R = S
    else S1 in
        S1 = {Transform S}
        {Iterate S1 IsDone Transform R}
    end
end
</pre></div>
<p>アキュムレータは入力と出力の状態の対になります．この場合において，<tt class="docutils literal">S</tt>と<tt class="docutils literal">R</tt>の対がアキュムレータとなっています．</p>
</div>
<div class="section" id="id4">
<h2>再帰的データ構造を扱う場合の反復計算</h2>
<p>再帰的データ構造を扱う計算をするときに，基本の場合と再帰の場合の二つの場合がありました．それを踏まえて，上述の反復計算を書き直すと次のようになります:</p>
<div class="highlight"><pre>proc {P X S1 ?Sn}
    if {BaseCase X} then
        S1 = Sn
    else
        {P1 ．．．S1 S2}
        ．．．
        {Pn ．．．Sm Sn}
    end
end
</pre></div>
<p>基本の場合(<tt class="docutils literal">{BaseCase X} == true</tt>の場合)は，既に状態変換の列の中で，一番最後の最終状態に居ることになるので，出力状態はそのままになります．</p>
<p>再帰の場合はいくつかの状態変換を施した後，再帰関数を呼んでいます．このとき，呼んでいる各関数もアキュムレータスタイルで書かれています．そのため，最後に呼ばれている関数では，その関数の出力状態がそのまま，呼び出し元の関数の出力状態<tt class="docutils literal">Sn</tt>になるようになっています．</p>
</div>
<div class="section" id="id5">
<h2>考察</h2>
<p>最後に再帰関数を呼ぶことによって，末尾再帰最適化がなされる(2章の練習問題で見たように，相互再帰では，自分自身の関数以外を呼んでもスタックが一定以上消費されない)のですが，その前に関数を呼んでしまうと，関数本体で一度しか再帰関数を呼ばないという条件を満たさなくなってしまうので，スタックを一定以上消費しないとは言えないと思います．</p>
<p>たぶんアキュムレータスタイルというのは，「再帰計算を反復計算にするときの一般的な形式」ではなく，「再帰計算を反復計算にした場合のスタイルを一般化した形式」として捉えるのが妥当だと思います．アキュムレータスタイルで，再帰の場合の本体で1つだけ相互再帰集合の関数を呼び出しており，かつその関数が本体の末尾に呼ばれているときのみ，スタックを一定以上消費しない反復計算になるのであって，それ以外の場合は「あまりメモリを消費しない」再帰計算にとどまると考えられます．このことについては，アキュムレータスタイルで書かれたマージソートのところでも「メモリ使用量は少ない」と述べられているだけなので，そういうことでしょう．再帰計算を反復計算にできる一般的な形式と思って読むと，なんでこれでスタックを消費しないと言えるの?と疑問に思ったりします．</p>
<p>Schemeでは再帰的データ構造としてリストに絞ったアキュムレータを提供していて，次のようになっています．</p>
<div class="highlight"><pre><span class="p">(</span><span class="k">define </span><span class="p">(</span><span class="nf">fold</span> <span class="nv">kcons</span> <span class="nv">knil</span> <span class="nv">l</span><span class="p">)</span>
  <span class="p">(</span><span class="k">let </span><span class="nv">loop</span> <span class="p">((</span><span class="nf">l</span> <span class="nv">l</span><span class="p">)</span> <span class="p">(</span><span class="nf">r</span> <span class="nv">knil</span><span class="p">))</span>
    <span class="p">(</span><span class="k">if </span><span class="p">(</span><span class="nb">null? </span><span class="nv">l</span><span class="p">)</span> <span class="nv">r</span>
        <span class="p">(</span><span class="nf">loop</span> <span class="p">(</span><span class="nb">cdr </span><span class="nv">l</span><span class="p">)</span> <span class="p">(</span><span class="nf">kcons</span> <span class="p">(</span><span class="nb">car </span><span class="nv">l</span><span class="p">)</span> <span class="nv">r</span><span class="p">)))))</span>
</pre></div>
<p>この場合のアキュムレータは<tt class="docutils literal">r</tt>になります．Schemeではすべて関数なので，出力状態を明示的に指定しなくても良く，対になっているように見えませんが，最後にきちんと<tt class="docutils literal">r</tt>を返しているので，ここからもアキュムレータが<tt class="docutils literal">r</tt>であることを確認できます．逆からたどると，初期状態は<tt class="docutils literal">knil</tt>となっていると言えます．<tt class="docutils literal">l</tt>はリストなので，<tt class="docutils literal">BaseCase</tt>にあたるものは<tt class="docutils literal">null?</tt>になっています．また，この場合は末尾で直接再帰になっているので，スタックを消費しません．</p>
<div class="section" id="id6">
<h3>蛇足</h3>
<p>Schemeの場合，ある関数を呼び出した後にやるべき計算を取り出せるという機能があって，それは(自分も含めて)多くの人の中で「強力そうなのは知っているが，正直なところそれがどういうもので，何に有効なのかよくわからない『継続』」として知られています．</p>
<p>関数型プログラミングは宣言的プログラミングにおける，部分値を扱うことを制限して，完全値のみで計算するようにした計算モデルなので，継続ってある計算をするために必要な完全値が計算ができないという理由により，その値を必要とする計算を取り出しておいて，いったん制御フローを他の部分に移すためのものとしてみれるのではないでしょうか．それ以外にも，今その値は存在しているけれども，それをつかって計算をするよりも先に別の計算をしたい場合のフロー制御としても使えるとは思いますが．</p>
</div>
</div>
</div>
        <hr />
    </div>



    <div class='article'>
        <div class="content-title">
            <a href="../2012/03/20/e72d8db8-7286-11e1-927a-040ccee352e6.html"><h1>Introduction to Domain TheoryのLecture1を読む</h1></a>
            <div class="metadata">
    <span class="label label-inverse">2012/03/20</span>
    <a href="../category/Articles.html" class="label label-info">Articles</a>
</div>        </div>

        <div><p>Graham Hutton先生の<a class="reference external" href="http://www.cs.nott.ac.uk/~gmh/domains.html">Introduction to Domain Theory</a>を読んだメモです。</p>
<div class="section" id="denotational-semantics">
<h2>Denotational Semantics</h2>
<p>BNFを使って形式的にAbstract syntaxが定義されたプログラミング言語Pを考えたときに、そのPのDenotational semanticsは次の二つから構成されるんだよーという話。</p>
<ol class="arabic">
<li><p class="first">a semantic domain for each syntactic category</p>
<p>ここでいうカテゴリーは、expressionとかcommandとか。</p>
</li>
<li><p class="first">a valuation function for each syntactic category</p>
<p>で、このvaluation functionっていうのはシンタックスの各フレーズに対して、
semantic domainの中の意味を割り当てるものですよー。</p>
</li>
</ol>
<p>で、なんかvaluation functionはhomomorphismじゃないといけないとしている。この
homomorphismであるということは、各フレーズの意味を割り当てるときは、そのフレーズの中のさらに小さいフレーズの意味から構成されるようなことらしい。で、一般的にはこういう性質のことを、compositionalityと言うらしい。</p>
</div>
<div class="section" id="foundational-problems">
<h2>Foundational Problems</h2>
<p>で、そもそもこのDomain Theoryがなんで生まれたのかというと、Denotational
semanticsがuntyped lambda-calculusに適切な意味を与えられなかったから、生まれたらしい。</p>
<p>で、じゃあ、なんで与えられなかったのか、というところについて、とりあえず単純に集合を使って、semantic domainを与えてみようじゃないかということをしてみる。その与えられなかった理由については、主に二つの理由があって:</p>
<ol class="arabic simple">
<li>recursively defined programs</li>
<li>recursively defined semantic domains</li>
</ol>
<p>についての問題らしい。</p>
<div class="section" id="recursively-defined-programs">
<h3>1. Recursively Defined Programs</h3>
<p>なんか直感的には無限ループになるようなプログラムを、ある集合上の関数として対応づけようとすると、そんな関数はネェってなったり、どんな関数でもそのプログラムに対応することになってしまったりして、困るという話。</p>
<p>この問題を扱うには「終了しない」ということをsemanticsのレベルで表す必要があるよね、とも言っている。</p>
</div>
<div class="section" id="recursively-defined-semantic-domains">
<h3>2. Recursively Defined Semantic Domains</h3>
<p>次は、関数とか手続きというものを値として扱えるようになったときに、じゃあ、そういった値ってどういう集合なんでしょうねー、関数って言うのは関数から関数への関数も関数なので、これじゃあ関数の集合っていうのが考えられないですよねーというお話。</p>
<p>で、関数の集合と同型な集合があればいいかなーとしてみても、やっぱり駄目で、ちょっと関数の集合の部分集合を考えてみても、濃度的に段違いなんですねー。あー、可算濃度とか対角線論法とか学部1年のときにやったなー。</p>
</div>
</div>
<div class="section" id="a-first-step-to-scott-domains-lifted-sets">
<h2>A First Step To Scott-Domains : Lifted Sets</h2>
<p>ということで、やっぱり集合をsemantic domainにするのは無理っぽいので、一つだけ、なんかエラーとか計算が終了しないとか未定義だとか、そういう値を導入しようということを、どえらい人は考えたんDA!</p>
<p>そういった値である、bottomというものを単純に一つ加えた集合をflat domainとか
lifted setとか呼ぶらしい。で、そういった集合では、bottomとそうじゃない値の間に、information orderingという関係が定義できるNE!と、言っている。で、このbottomを含んだ集合をsemantic domainとすると、さっきの1. Recursively Defined
Programsで問題にしていた、終了しないプログラムに意味が与えられるらしい。</p>
</div>
<div class="section" id="partial-orderings">
<h2>Partial Orderings</h2>
<p>じゃあ、もうちょっと複雑にして、いくつかの値をとるような関数というものを考えてみよう、という話。とりあえず、2引数の関数はそれぞれの引数の集合の直積を引数にとる関数と考えられる。</p>
<p>このとき、それぞれの引数の集合が、flat domainだったら、その直積上にも
information orderingを考えることができる。で、こういう直積はflat setsではなくてpartially ordered sets(posets)になるね。posetsだから、反射律、対称律、推移律が成り立つ。もっというと、bottomというものはbasepointというものらしいので、こういった直積が入ったりすることを考えると、semantic domainsはpointed posetsということができるらしい。</p>
</div>
<div class="section" id="monotonic-functions">
<h2>Monotonic Functions</h2>
<p>ということで、semantic domainsを(pointed) posetsにするとすると、プログラムは、そういったposets上の関数としてモデル化できるはず。でも、そういった関数すべてがプログラムのモデルとしてふさわしいわけじゃない。</p>
<p>ここからがよくわからなかったんだけれども、入力と出力で、information orderingが保存されることを要求されるらしい。で、こういった関数のことを、monotonicと呼ぶらしい。</p>
<p>なんかこの、計算可能な関数はmonotonicであるとか、情報がたくさんあった方が結果の情報もたくさんあるというのがよくわからない。じゃあ、逆にmonotonicじゃないと何がまずいのか、とかもよくわからない。</p>
</div>
<div class="section" id="excercises">
<h2>Excercises</h2>
<ul>
<li><pre class="first literal-block">
E[[proc C]]sigma = proc C
E[[I]]sigma =  C[[C]]sigma (if I = proc C)
             | sigma(I) (otherwise)
</pre>
</li>
<li><p class="first">3-&gt;3 を書き下すとたぶん10個</p>
</li>
<li><p class="first">N-&gt;M の数は:</p>
<pre class="literal-block">
F(N, M) =   1 (if M = 1)
          | M (if N = 1)
          | F(N, M-1) + F(N-1, M)
</pre>
</li>
</ul>
<p>最後の問題は、chainの元のN個のポイントのうち、一番下のポイントが、M個のポイントのどこに写されるのかで場合分けする。</p>
<ol class="arabic">
<li><p class="first">一番下のポイントが先のM個のポイントのうち、一番下以外に写される。</p>
<p>その数は<tt class="docutils literal">F(N, <span class="pre">M-1)</span></tt>と等しい。</p>
</li>
<li><p class="first">一番下のポイントが先のM個のポイントのうち、一番下に写される。</p>
<p>このとき、別に残りのN-1個のポイントがどう写されようと、その対応関係が、
(N-1)-&gt;Mのmonotonic functionであれば、N-1個のポイントの一番下にもう一個付け加えて、それがM個のポイントの一番下に写されたものもmonotonic functionになる。つまり、この場合は(N-1)-&gt;Mのすべてのmonotonic functionの一番下に割り当てを追加してあげれば良いだけ。ということは、その数は<tt class="docutils literal"><span class="pre">F(N-1,</span> M)</tt>と等しいということになる。</p>
</li>
</ol>
</div>
</div>
        <hr />
    </div>


     <div class="pagination">
<ul>
    <li class="prev"><a href="../author/draftcode4.html">&larr; Previous</a></li>

    <li class=""><a href="../author/draftcode.html">1</a></li>
    <li class=""><a href="../author/draftcode2.html">2</a></li>
    <li class=""><a href="../author/draftcode3.html">3</a></li>
    <li class=""><a href="../author/draftcode4.html">4</a></li>
    <li class="active"><a href="../author/draftcode5.html">5</a></li>
    <li class=""><a href="../author/draftcode6.html">6</a></li>

    <li class="next"><a href="../author/draftcode6.html">Next &rarr;</a></li>

</ul>
</div> 
</div>

<div id="footer">
    <div id="about">
        <ul class="nav nav-list">
            <li class="nav-header">About the author</li>
        </ul>

        <div style="padding: 10px;">
            <a id="about-image" href="../pages/about.html" rel="alternate"><img src="../static/images/draftcode.png" style="width: 100.0px; height: 100.0px;"/></a>
            <p>東京で情報工学を専攻している大学院生です。</p>
        </div>
    </div>

    <div id="site">
        <ul class="nav nav-list">
            <li class="nav-header">Site</li>

            <li><a href="../archives.html">Archives</a>
            <li><a href="../atom.xml" rel="alternate">Atom feed</a></li>
        </ul>
    </div>

    <div id="category">
        <ul class="nav nav-list">
            <li class="nav-header">Categories</li>
                        <li><a href="../category/android.html">Android</a></li>            <li><a href="../category/articles.html">Articles</a></li>            <li><a href="../category/java.html">Java</a></li>            <li><a href="../category/python.html">Python</a></li>        </ul>
    </div>

    <div id="social">
        <ul class="nav nav-list">
            <li class="nav-header">Social</li>
                        <li class="social"><a href="http://twitter.com/#!/draftcode">Twitter</a></li>            <li class="social"><a href="http://github.com/draftcode">GitHub</a></li>            <li class="social"><a href="https://plus.google.com/107177890582465029754?rel=author">Google+</a></li>        </ul>
    </div>
</div>

</body>
</html>